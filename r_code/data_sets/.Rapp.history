familias[1,]
familias[,1]
mean(familias[,1])
mean(familias[,2])
mean(familias[,3])
mean(familias[,4])
cov(familias)
cov(familias[,1:2], familias[,3:4])
par(mfrow=c(2,2))
fam1=familias[,1:2]
fam1
plot(fam1, xlab="(a) Datos originales", ylab="", asp=1)
fam1
med
med(fam1)
points(med[1], med[2], pch=19, col="blue")
med=mean(fam1)
med=c(mean(fam1[,1], mean(fam1[,1])))
points(med[1], med[2], pch=19, col="blue")
points(med[1], med[2], pch=19, col="red")
par(mfrow=c(2,2))#
#
#Representaci??n de los datos originales#
#
fam1=familias[,1:2]#
med=mean(fam1)#
plot(fam1, xlab="(a) Datos originales", ylab="", asp=1)
fam1
mean(fam1[,1])
a=mean(fam1[,1])
b=mean(fam1[,1])
points(a,b, pch=19, col="blue")
med[1]
fam1c=cbind(fam1[,1]-a, fam1[,2]-b)
fam1c
plot(fam1c, xlab="(b) Datos centrados", ylab="", asp=1)
med1c=apply(fam1c, 2, mean)
med1c
points(med1c[1]], med1c[2], pch=19, col="blue")
points(med1c[1], med1c[2], pch=19, col="blue")
cov=(fam1)
sc=cov(fam1)
sc
cov(familias[,1:2], familias[,3:4])
sc
fam_1
fam1
fam1c
fam1_est_uni=fam1c%*%diag(1/sqrt(diag(sc)))
plot(fam1_est_uni, xlab="(c) Estandarizaci??n univariante", ylab="", asp=1)
auto=eigen(sc)
auto
auto$vectors
autovectors[1]
values
eigen$values
auto$values
a=sqrt(auto$values)
b=1/a
b
a
c=auto$vectors
c
c+1
sigma12=c*b*t(c)
sigma12
diag(b)
sigma12=c*diag(b)*t(c)
sigma12
#Matriz de estandarizaci??n multivariante#
auto=eigen(sc)#
v=auto$vectors#
lambda=auto$values#
scm12=v%*%diag(1/sqrt(lambda))%*%t(v)
sigma12=t(c)*diag(b)*c
sgma12
sigma12
t(sigma12)
t(scm12%*%t(fam1c))
plot(fam1_est_multi, xlab="(d) Estandarizaci??n bivariante", ylab="", asp=1)#
points(med1c[1], med1c[2], pch=19, col="blue")#
par(mfrow=c(1,1))
#Estandarizaci??n multivariante#
fam1_est_multi=t(scm12%*%t(fam1c))#
plot(fam1_est_multi, xlab="(d) Estandarizaci??n bivariante", ylab="", asp=1)#
points(med1c[1], med1c[2], pch=19, col="blue")#
par(mfrow=c(1,1))
2900-0.2*2900
2900-0.15*2900
2400*!4
2400*14
66.4+13.75*72+5*172-6.7*24
1755*1.55
a<-c(4, 5, 6, 7, 9)
b<-c(5, 6, 7, 8)
a
b
model<-lm(a~b)
? lm
lm(a~b)
b<-c(5, 6, 7, 8, 9)
model<-lm(a~b)
model
summary(model)
coef(model)
omega_t<-seq(0.000333, 0.1, length=20000)#
r<-1/omega_t#
omega<-rnorm(20000, mean=omega_t, sd=0.0003)#
rho<-1/omega#
difomega<-omega-omega_t#
#Pasamos difomega a milisegundos de arco#
difomegamas<-difomega*1000#
difdis<-rho-r#
#Pasamos difdis a Kp#
difdiskpc<-difdis/1000#
par(mfrow=c(1,2))#
hist(difomegamas, breaks=30, col='3')#
hist(difdiskpc, xlim=c(-1, 0.4), breaks=30, col='blue')
install.packages('Rcmdp')
which -aR
install.packages('Rcmdp')
version
install.packages('Rcmdp')
install.packages('Rcmdr')
library(Rcmdr)
n1 <- 20
n1 <- 20#
n2 <- 20#
k <- seq(1, n1)#
l <- seq(1, n2)#
matrix <- t(matrix(numeric(n1)))#
auxiliary <- numeric(n2)#
for (i in k) {#
  for (j in l) {#
    auxiliary[j] = 1/(pi^4*i^2*j^2)#
  }#
  matrix <- rbind(matrix, auxiliary)#
}#
matrix <- matrix[-1,]#
dim(matrix)#
#
coefficients <- as.vector(t(matrix)) # Vector storing the <<first>> n1*n2 coefficients of the infinite sum #
#
set.seed(27)#
sample <- numeric(10^5)#
for ( i in 1:length(sample)) {#
chisq <- rchisq(n1*n2, df = 1) #
sample[i] <- sum(coefficients*chisq)#
}#
#
q <- quantile(sample, probs = c(0.99, 0.98, 0.95, 0.90, 0.80))#
q0.01 <- q[1]#
q0.05 <- q[3]#
q0.10 <- q[4]#
#
########## COMPARISON OF TESTS BASED ON THE EMPIRICAL COPULA, KENDAL'S TAU AND SPEARMAN'S RHO #
#
# Function to compute empirical copula at u = c(u1, u2)#
#
set.seed(27)#
n <- 100#
x <- rnorm(n)#
y <- rnorm(n)#
Cn <- function(u){#
  mean((rank(x)/(n+1) <= u[1] )*(rank(y)/(n+1) <= u[2]))#
}#
#
# Computation of CramÃ©r-von Mises statistic#
library(cubature)#
integrando <- function(u){#
  (Cn(u)-u[1]*u[2])^2#
}#
#
# Sys.time()#
D_statistic <- n*adaptIntegrate(integrando, lowerLimit = c(0, 0), upperLimit = c(1, 1), absError = 0.00001)$integral#
# Sys.time()#
D_statistic#
n1 <- 60#
n2 <- n1#
grid1 <- seq(0, 1, length =  n1) # There are (n-1) x (n-1) rectangles in the grid #
grid2d <- data.frame(expand.grid(grid1, grid1))#
area <- (1/(n1-1))^2#
rieman <- apply(grid2d, 1, integrando)#
D_statistic <- n*sum(rieman*area)#
D_statistic
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 2000 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rchisq(n, df = 4) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- -rchisq(n, df = 4) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  #p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10
set.seed(27)#
M <- 10^4 # Number of simulations#
n <- 10 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
#
}#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 10 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
#
}#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 10 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 20 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 50 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 100 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 200 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 500 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
set.seed(27)#
M <- 1000 # Number of simulations#
n <- 2000 # Sample size#
#
X <- matrix(nrow = M, ncol = n)#
Y <- matrix(nrow = M, ncol = n)#
#
for (i in 1:M) {#
  X[i,] <- rexp(n) # We could change mean and sd as desired #
}#
#
for (i in 1:M) {#
  Y[i,] <- rgamma(n, 3, 2) # We could change mean and sd as desired #
}#
#
# Vector that is going to store the p-values #
p_values_tau <- numeric(M)#
p_values_rho <- numeric(M)#
# p_values_copula <- numeric(M)#
c_v_m <- numeric(M)#
#
for (i in 1:M) {#
  p_values_tau[i] <- cor.test(X[i,], Y[i,], method = 'kendall', alternative = 'two.sided')$p.value#
  p_values_rho[i] <- cor.test(X[i,], Y[i,], method = 'spearman', alternative = 'two.sided')$p.value#
  # p_values_copula[i] <- indepTest(data.frame(X[i,], Y[i,]), d)$global.statistic.pvalue#
  Cn <- function(u){#
    mean((rank(X[i,])/(n+1) <= u[1] )*( rank(Y[i,])/(n+1) <= u[2]))#
  }#
  integrando <- function(u){#
    (Cn(u)-u[1]*u[2])^2#
  }#
  rieman <- apply(grid2d, 1, integrando)#
  c_v_m[i] <- n*sum(rieman*area)#
  }#
length(which(p_values_tau < 0.01))/length(p_values_tau) # Power when alpha = 0.01#
#length(which(p_values_tau < 0.02))/length(p_values_tau) # Power when alpha = 0.02#
length(which(p_values_tau < 0.05))/length(p_values_tau) # Power when alpha = 0.05#
length(which(p_values_tau < 0.10))/length(p_values_tau) # Power when alpha = 0.10#
#length(which(p_values_tau < 0.20))/length(p_values_tau) # Power when alpha = 0.20#
#
length(which(p_values_rho < 0.01))/length(p_values_rho) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(p_values_rho < 0.05))/length(p_values_rho) # Power when alpha = 0.05#
length(which(p_values_rho < 0.10))/length(p_values_rho) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
#length(which(p_values_copula < 0.01))/length(p_values_copula) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
#length(which(p_values_copula < 0.05))/length(p_values_copula) # Power when alpha = 0.05#
#length(which(p_values_copula < 0.10))/length(p_values_copula) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20#
#
length(which(c_v_m > q0.01))/length(c_v_m) # Power when alpha = 0.01#
#length(which(p_values_rho < 0.02))/length(p_values_rho) # Power when alpha = 0.02#
length(which(c_v_m > q0.05))/length(c_v_m) # Power when alpha = 0.05#
length(which(c_v_m > q0.10))/length(c_v_m) # Power when alpha = 0.10#
#length(which(p_values_rho < 0.20))/length(p_values_rho) # Power when alpha = 0.20
x <- runif(-3, 3)
x <- runif(, 10000,-3, 3)
x <- runif(10000,-3, 3)
rnorm(x)
clear
clc
x <- runif(10000, -3, 3)
max(x);min(x)
length(which(x < 1 & x > -1))
length(which(x < -2 & x > -3))
length(which(x < -1 & x > -3))
99949 + 9499459594
a-pchisq(3, df = 1)
1-pchisq(3, df = 1)
pchisq(5)
pchisq(5, 1)
pchisq(6, df = 1)
pchisq(7, df = 1)
'juju'
'Carballito'
'El lugar donde moran los datos'
a <- rchisq(100000)
a <- rchisq(100000, df = 1)
length(a > 7)
length(which(a > 7))
799/100000
1-pchisq(7, df = 1)
install.packages('xtable')
'juju'
a <- data.frame(x <- c(1, 1), y <- c(8, 9))
a
xtable(a)
library(xtable)
xtable(a)
install.packages('kernelboot')
library(kernelboot)
a <- c(1, 4, 5, 6, 7, 8)
a
kernelboot(a)
save.image()
load(".RData")
save.image()
getwd
getwd()
'jiji'
"juju"
sewwd('/home/')
getwd()
?setwd
K_dist <- function(u){
K_dist <- function(u){#
  1 - abs(u)#
}#
#
K_inf <- function(u){#
  1#
}#
K_gauss <- function(u){#
  exp((-abs(u)^2)/(2*0.2^2))#
}#
#
K_laplace <- function(u){#
  a <- sqrt(2*0.2^2)#
  (a^2)/(a^2+u)#
}#
#
K_unif <- function(u){#
  a <- sqrt(2*0.2^2)#
  (sin(a*u))/(a*u)#
}
porcentaje_rechazo_norm1 <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- xmin + sqrt(desv)*rnorm(n)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- xmin + sin(2*3.141592*xmin) + sqrt(desv)*rnorm(n)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}#
#
porcentaje_rechazo_norm_2 <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- xmin + sqrt(desv)*rnorm(n)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- 1/2 + sqrt(desv)*rnorm(n)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}#
porcentaje_rechazo_norm_3 <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- sin(2*pi*xmin) + sqrt(desv)*rnorm(n)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- 1/2 + sqrt(desv)*rnorm(n)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}#
porcentaje_rechazo_ji <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
tabla <- numeric()#
for (simu in 1:B){#
X <- numeric()#
Y <- numeric()#
for (curvas in 1:((1-eps)*p)){#
  xmin <- runif(n)#
  ymin <- xmin + sqrt(desv)*((rchisq(n, df=1)-1)/2)#
  X <- rbind(X, xmin)#
  Y <- rbind(Y, ymin)#
}#
#
if (eps > 0){#
  for (curvas in 1:((eps)*p)){#
    xmin <- runif(n)#
    ymin <- xmin + sin(2*3.141592*xmin) + sqrt(desv)*((rchisq(n, df=1)-1)/2)#
    X <- rbind(X, xmin)#
    Y <- rbind(Y, ymin)#
  }#
}#
#
delta <- matrix(ncol=p, nrow=p)#
for (i in 1:p){#
  for (k in 1:p){#
    suma1 <- 0#
    suma2 <- 0#
    suma3 <- 0#
    for (j in 1:n){#
      for (l in c(1:n)[-j]){#
        suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
        suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
      }#
      for (l in 1:n){#
        suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
      }#
    }#
    delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
  }#
}#
#
delta2 <- delta#
for (i in 1:p){#
  delta2[i,i] <- 0#
}#
#
Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
Tp#
#
h <- delta2#
g <- apply(delta2, 2, sum)#
g <- (1/(p-1))*g#
sigma <- var(2*g)#
sigma <- sqrt(sigma)#
#
estadistico <- (sqrt(p)*Tp)/sigma#
tabla <- c(tabla, estadistico)#
#
}#
#
tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
return((sum(tabla)/B))#
}#
#
porcentaje_rechazo_sin_ji <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- sin(2*3.141592*xmin) + sqrt(desv)*((rchisq(n, df=1)-1)/2)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- xmin + sin(2*3.141592*xmin) + sqrt(desv)*((rchisq(n, df=1)-1)/2)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}#
#
porcentaje_rechazo_t <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- xmin + sqrt(desv)*((rt(n, df=3))/1.73)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- xmin + sin(2*3.141592*xmin) + sqrt(desv)*((rt(n, df=3))/1.73)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}#
#
porcentaje_rechazo_sin_t <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- sin(2*3.141592*xmin) + sqrt(desv)*((rt(n, df=3))/1.73)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- xmin + sin(2*3.141592*xmin) + sqrt(desv)*((rt(n, df=3))/1.73)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}
vector_1 <- numeric(4)
vector_1 <- numeric(4)#
vector_2 <- numeric(4)#
vector_3 <- numeric(4)
vector_1
time0 <- Sys.time()#
for (i in 1:4) {#
  vector_1[i] <- porcentaje_rechazo_norm1(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}#
#
save(vector_1, file = 'vector1.RData')#
time01 <- Sys.time()
epsilon <- c(0.01, 0.03, 0.05, 0.07, 0.09)
time0 <- Sys.time()#
for (i in 1:4) {#
  vector_1[i] <- porcentaje_rechazo_norm1(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}#
#
save(vector_1, file = 'vector1.RData')#
time01 <- Sys.time()
vector_1
epsilon
epsilon <- c(0.09, 0.11, 0.13, 0.15, 0.17, 0.19)
time0 <- Sys.time()
epsilon
vector_1 <- numeric(6)
time0 <- Sys.time()#
for (i in 1:6) {#
  vector_1[i] <- porcentaje_rechazo_norm1(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}#
#
save(vector_1, file = 'vector1.RData')#
time01 <- Sys.time()
vector_1
clear
clc
epsilon <- c(0.01, 0.03, 0.05, 0.07, 0.09, 0.11, 0.13, 0.15, 0.17, 0.19)#
vector_1 <- numeric(10)#
vector_2 <- numeric(10)#
vector_3 <- numeric(10)
for (i in 1:10) {#
  vector_2[i] <- porcentaje_rechazo_norm2(n = 5, p = 200, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
porcentaje_rechazo_norm1
porcentaje_rechazo_norm_2 <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- xmin + sqrt(desv)*rnorm(n)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- 1/2 + sqrt(desv)*rnorm(n)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}
epsilon
for (i in 1:10) {#
  vector_2[i] <- porcentaje_rechazo_norm2(n = 5, p = 200, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
for (i in 1:10) {#
  vector_2[i] <- porcentaje_rechazo_norm_2(n = 5, p = 200, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
vector_""
vector_2
vector_2 <- numeric(10)
for (i in 1:10) {#
  vector_2[i] <- porcentaje_rechazo_norm_2(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
vector_2
porcentaje_rechazo_norm_2(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = 0.5)
porcentaje_rechazo_norm_2(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = 0.75)
epsilon <- c(0.21, 0.23, 0.25, 0.27)
vector_2 <- numeric(4)
for (i in 1:10) {#
    vector_2[i] <- porcentaje_rechazo_norm_2(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
   }
vector_2
epsilon <- c(0. 73, 0.75, 0.77, 0.79, 0.81 , 0.83, 0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97, 0.99)
epsilon <- c(0.73, 0.75, 0.77, 0.79, 0.81 , 0.83, 0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97, 0.99)
porcentaje_rechazo_norm_3
vector_3 <- numeric(14)
for (i in 1:14) {#
 +   vector_3[i] <- porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
+ }
for (i in 1:14) {#
   vector_3[i] <- porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
vector_3
vector_2
.Rhistory
vector_3
history(Inf)
history
history()
objects()
newaltitud
f
gamma
a
y
objects()
vector_3
porcentaje_rechazo_norm_porcentaje_rechazo_norm_3 <- function(r = 2, n, p, alpha, desv, K, B, eps){#
  set.seed(1423)#
  pnr <- 1#
  for (i in (r-1):0){#
    pnr = pnr*(n-i)#
  }#
  tabla <- numeric()#
  for (simu in 1:B){#
    X <- numeric()#
    Y <- numeric()#
    for (curvas in 1:((1-eps)*p)){#
      xmin <- runif(n)#
      ymin <- sin(2*pi*xmin) + sqrt(desv)*rnorm(n)#
      X <- rbind(X, xmin)#
      Y <- rbind(Y, ymin)#
    }#
    if (eps > 0){#
      for (curvas in 1:((eps)*p)){#
        xmin <- runif(n)#
        ymin <- 1/2 + sqrt(desv)*rnorm(n)#
        X <- rbind(X, xmin)#
        Y <- rbind(Y, ymin)#
      }#
    }#
    delta <- matrix(ncol=p, nrow=p)#
    for (i in 1:p){#
      for (k in 1:p){#
        suma1 <- 0#
        suma2 <- 0#
        suma3 <- 0#
        for (j in 1:n){#
          for (l in c(1:n)[-j]){#
            suma1 <- suma1 + Y[i,j]*Y[i,l]*K(X[i,j]-X[i,l])#
            suma2 <- suma2 + Y[k,j]*Y[k,l]*K(X[k,j]-X[k,l])#
          }#
          for (l in 1:n){#
            suma3 <- suma3 + Y[i,j]*Y[k,l]*K(X[i,j]-X[k,l])#
          }#
        }#
        delta[i,k] <- (1/pnr)*suma1 + (1/pnr)*suma2 - (2/(n*n))*suma3#
      }#
    }#
    delta2 <- delta#
    for (i in 1:p){#
      delta2[i,i] <- 0#
    }#
    Tp <-(1/(p*(p-1)))*sum(apply(delta2, 1, sum))#
    Tp#
    h <- delta2#
    g <- apply(delta2, 2, sum)#
    g <- (1/(p-1))*g#
    sigma <- var(2*g)#
    sigma <- sqrt(sigma)#
    estadistico <- (sqrt(p)*Tp)/sigma#
    tabla <- c(tabla, estadistico)#
  }#
  tabla <- ifelse(tabla > qnorm(1-alpha), 1, 0)#
  return((sum(tabla)/B))#
}
epsilon <- c(0.73, 0.75, 0.77, 0.79, 0.81 , 0.83, 0.85, 0.87, 0.89, 0.91, 0.93, 0.95, 0.97, 0.99)
vector_3 <- numeric(14)
for (i in 1:14) {#
   vector_3[i] <- porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
for (i in 1:14) {#
   vector_3[i] <- porcentaje_rechazo_norm_porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
K_gauss <- function(u){#
  exp((-abs(u)^2)/(2*0.2^2))#
}
for (i in 1:14) {#
   vector_3[i] <- porcentaje_rechazo_norm_porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
desv
desv <- 0.5
for (i in 1:14) {#
   vector_3[i] <- porcentaje_rechazo_norm_porcentaje_rechazo_norm_3(n = 5, p = 300, alpha = 0.05, desv = 0.5, K = K_gauss, B = 100, eps = epsilon[i])#
}
vector_3
install.packages('BwQuant')
library(BwQuant)
install.packages('package.lib')
pararell:detectCores()
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.95)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.98)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.99)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
# Preparation of dataset Libras #
#
libras <- read.csv('libras.txt', header = F)#
colnames(libras) <- NULL#
# We have to obtain 360 MTS of length 45, each one with a label from 1 to 15 (there are 15 clusters)#
#
S <- vector(mode = "list", length = nrow(libras))#
#
# S is going to contain each MTS with its label#
#
for (i in 1 : length(S)) {#
  # S[[i]] <- pendigits[i,] #
  S1 <- libras[i, c(seq(1, 90, by = 2), 91)] #
  S2 <- libras[i, c(seq(2, 90, by = 2), 91)]#
  S[[i]] <- rbind(as.numeric(S1), as.numeric(S2))#
}#
#
save(S, file = 'libras.RData')#
# Fuzzy C-means and clustering validation#
#
# Removing the labels from S#
M <- vector(mode = "list", length = length(S))#
for (i in 1:length(S)) {#
  M[[i]] <- S[[i]][,seq(1, 45)]#
}#
#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzy_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/sw_distance_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/vpca_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/fuzzytocrisp_function.R')#
source('/Users/angellopezoriona/Library/Mobile Documents/com~apple~CloudDocs/git_hub/PhD_degree/r_code/algorithms/vpca/kmeans_function.R')#
#
# Dimensionality reductions vpca#
#
Y <- vpca(M, lambda = 0.99)#
#
# Implementation of fuzzy c-means algorithm#
#
u <- km_mts(Y = Y, K = 15, niter = 20, tol = 0.01, dis = sw_distance)#
clustering <- fuzzytocrisp(u)#
ground_truth <- numeric(length(Y))#
#
for (j in 1 : length(Y)) {#
  ground_truth[j] <- S[[j]][1, 46]#
}#
#
library(dtwclust)#
cvi(ground_truth, clustering)
